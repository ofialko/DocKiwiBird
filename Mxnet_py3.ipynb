{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::927962595994:role/service-role/AmazonSageMaker-ExecutionRole-20181220T142845\n",
      "CPU times: user 108 ms, sys: 17.3 ms, total: 125 ms\n",
      "Wall time: 946 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from utils import *\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket = 'ofs3test'\n",
    "prefix = 'ic-lstformat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544295431143.dkr.ecr.ap-southeast-2.amazonaws.com/image-classification:latest\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# Tool for creating lst file\n",
    "download('https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp -r data data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -l data_valid/kiwi | wc -l\n",
    "ls -l data_valid/no_kiwi | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746268656716418"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200/268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p data_train\n",
    "mkdir -p data_train/kiwi\n",
    "for j in `ls data_valid/kiwi/*.png | shuf | head -n 200`; do\n",
    "    mv $j data_train/kiwi/\n",
    "done\n",
    "\n",
    "mkdir -p data_train/no_kiwi\n",
    "for j in `ls data_valid/no_kiwi/*.png | shuf | head -n 588`; do\n",
    "    mv $j data_train/no_kiwi/\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data_train/kiwi/.ipynb_checkpoints'\n",
    "if os.path.exists(PATH):\n",
    "    rm_rf(PATH)\n",
    "PATH = 'data_train/no_kiwi/.ipynb_checkpoints'\n",
    "if os.path.exists(PATH):\n",
    "    rm_rf(PATH)\n",
    "    \n",
    "PATH = 'data_valid/kiwi/.ipynb_checkpoints'\n",
    "if os.path.exists(PATH):\n",
    "    rm_rf(PATH)\n",
    "PATH = 'data_valid/no_kiwi/.ipynb_checkpoints'\n",
    "if os.path.exists(PATH):\n",
    "    rm_rf(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kiwi 0\n",
      "no_kiwi 1\n",
      "kiwi 0\n",
      "no_kiwi 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python im2rec.py --list --recursive data-train-lst data_train/\n",
    "python im2rec.py --list --recursive data-val-lst data_valid/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\t1.000000\tno_kiwi/20180414_205504.wav.png.IMG-110.png\n",
      "109\t1.000000\tno_kiwi/20180422_221006.wav.png.IMG-066.png\n",
      "124\t1.000000\tno_kiwi/20180422_221006.wav.png.IMG-126.png\n",
      "21\t0.000000\tkiwi/I160_BIRX_161205_011325.wav.png.IMG-032.png\n",
      "97\t1.000000\tno_kiwi/20180414_205504.wav.png.IMG-122.png\n",
      "164\t1.000000\tno_kiwi/20180522_185007.wav.png.IMG-013.png\n",
      "191\t1.000000\tno_kiwi/20180522_185007.wav.png.IMG-105.png\n",
      "146\t1.000000\tno_kiwi/20180423_222506.wav.png.IMG-085.png\n",
      "224\t1.000000\tno_kiwi/K157_BIRX_161030_035734.wav.png.IMG-084.png\n",
      "226\t1.000000\tno_kiwi/L157_BIRX_161030_045715.wav.png.IMG-122.png\n",
      "140\t1.000000\tno_kiwi/20180423_222506.wav.png.IMG-073.png\n",
      "81\t1.000000\tno_kiwi/20180414_205504.wav.png.IMG-052.png\n",
      "169\t1.000000\tno_kiwi/20180522_185007.wav.png.IMG-025.png\n",
      "66\t0.000000\tkiwi/R151_BIRP_170218_042726.wav.png.IMG-036.png\n",
      "147\t1.000000\tno_kiwi/20180423_222506.wav.png.IMG-090.png\n",
      "162\t1.000000\tno_kiwi/20180522_185007.wav.png.IMG-010.png\n",
      "178\t1.000000\tno_kiwi/20180522_185007.wav.png.IMG-058.png\n",
      "107\t1.000000\tno_kiwi/20180422_221006.wav.png.IMG-062.png\n",
      "7\t0.000000\tkiwi/F164_BIRX_170324_001343.wav.png.IMG-003.png\n",
      "19\t0.000000\tkiwi/F164_BIRX_170324_052707.wav.png.IMG-057.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 ./data-val-lst.lst > example.lst\n",
    "f = open('example.lst','r')\n",
    "lst_content = f.read()\n",
    "print(lst_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four channels: train, validation, train_lst, and validation_lst\n",
    "s3train = 's3://{}/{}/train/'.format(bucket, prefix)\n",
    "s3validation = 's3://{}/{}/validation/'.format(bucket, prefix)\n",
    "s3train_lst = 's3://{}/{}/train_lst/'.format(bucket, prefix)\n",
    "s3validation_lst = 's3://{}/{}/validation_lst/'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the image files to train and validation channels\n",
    "!aws s3 cp data_train/ $s3train --recursive --quiet\n",
    "!aws s3 cp data/ $s3validation --recursive --quiet\n",
    "\n",
    "# upload the lst files to train_lst and validation_lst channels\n",
    "!aws s3 cp data-train-lst.lst $s3train_lst --quiet\n",
    "!aws s3 cp data-val-lst.lst $s3validation_lst --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588\n"
     ]
    }
   ],
   "source": [
    "!ls data_train/no_kiwi/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p2.xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n",
    "\n",
    "ic.set_hyperparameters(num_layers=18,\n",
    "                             use_pretrained_model=0,\n",
    "                             image_shape = \"3,64,64\",\n",
    "                             num_classes=2,\n",
    "                             mini_batch_size=32,\n",
    "                             epochs=15,\n",
    "                             learning_rate=0.01,\n",
    "                             top_k=2,\n",
    "                             #resize = 256,\n",
    "                             num_training_samples=788,\n",
    "                             precision_dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3train, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3validation, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "train_data_lst = sagemaker.session.s3_input(s3train_lst, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_data_lst = sagemaker.session.s3_input(s3validation_lst, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data, \n",
    "                 'train_lst': train_data_lst, 'validation_lst': validation_data_lst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: image-classification-2019-01-11-01-29-14-953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-11 01:29:15 Starting - Starting the training job...\n",
      "2019-01-11 01:29:18 Starting - Launching requested ML instances......\n",
      "2019-01-11 01:30:18 Starting - Preparing the instances for training......\n",
      "2019-01-11 01:31:27 Downloading - Downloading input data...\n",
      "2019-01-11 01:31:51 Training - Downloading the training image........\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:23 INFO 140539772897088] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:23 Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:23 Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.01', u'top_k': u'2', u'use_pretrained_model': u'0', u'epochs': u'15', u'num_training_samples': u'788', u'num_layers': u'18', u'image_shape': u'3,64,64', u'mini_batch_size': u'32', u'precision_dtype': u'float32', u'num_classes': u'2'}\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:23 INFO 140539772897088] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.01', u'top_k': u'2', u'use_pretrained_model': u'0', u'epochs': u'15', u'num_training_samples': u'788', u'num_layers': u'18', u'image_shape': u'3,64,64', u'mini_batch_size': u'32', u'precision_dtype': u'float32', u'num_classes': u'2'}\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:23 Final configuration: {u'top_k': u'2', u'optimizer': u'sgd', u'learning_rate': u'0.01', u'epochs': u'15', u'lr_scheduler_factor': 0.1, u'num_layers': u'18', u'precision_dtype': u'float32', u'mini_batch_size': u'32', u'num_classes': u'2', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'0', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,64,64', u'gamma': 0.9, u'num_training_samples': u'788'}\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:23 INFO 140539772897088] Final configuration: {u'top_k': u'2', u'optimizer': u'sgd', u'learning_rate': u'0.01', u'epochs': u'15', u'lr_scheduler_factor': 0.1, u'num_layers': u'18', u'precision_dtype': u'float32', u'mini_batch_size': u'32', u'num_classes': u'2', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'0', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,64,64', u'gamma': 0.9, u'num_training_samples': u'788'}\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:23 INFO 140539772897088] Creating record files for data-train-lst.lst\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:23 Creating record files for data-train-lst.lst\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 Done creating record files...\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] Done creating record files...\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 Creating record files for data-val-lst.lst\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] Creating record files for data-val-lst.lst\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 Done creating record files...\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] Done creating record files...\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 Performing random weight initialization\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] Performing random weight initialization\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 ---- Parameters ----\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] ---- Parameters ----\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] num_layers: 18\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 num_layers: 18\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 epochs: 15\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] epochs: 15\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] optimizer: sgd\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 optimizer: sgd\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 momentum: 0.900000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] momentum: 0.900000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 weight_decay: 0.000100\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] weight_decay: 0.000100\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 learning_rate: 0.010000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] learning_rate: 0.010000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] lr_scheduler_step defined without lr_scheduler_factor, will be ignored...\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 lr_scheduler_step defined without lr_scheduler_factor, will be ignored...\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 mini_batch_size: 32\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 image_shape: 3,64,64\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] mini_batch_size: 32\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] image_shape: 3,64,64\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 num_classes: 2\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] num_classes: 2\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 num_training_samples: 788\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] num_training_samples: 788\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 augmentation_type: None\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] augmentation_type: None\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] kv_store: device\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] top_k: 2\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] multi_label: 0\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] --------------------\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 kv_store: device\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 top_k: 2\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 multi_label: 0\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 --------------------\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:24 Setting number of threads: 3\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:24 INFO 140539772897088] Setting number of threads: 3\u001b[0m\n",
      "\u001b[31m[01:33:28] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-master.349.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:31 Epoch[0] Batch [20]#011Speed: 223.728 samples/sec#011accuracy=0.794643#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:31 INFO 140539772897088] Epoch[0] Batch [20]#011Speed: 223.728 samples/sec#011accuracy=0.794643#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:31 Epoch[0] Train-accuracy=0.811198\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:31 INFO 140539772897088] Epoch[0] Train-accuracy=0.811198\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:31 Epoch[0] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:31 INFO 140539772897088] Epoch[0] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:31 Epoch[0] Time cost=3.004\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:31 INFO 140539772897088] Epoch[0] Time cost=3.004\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:31 Epoch[0] Validation-accuracy=0.636719\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:31 INFO 140539772897088] Epoch[0] Validation-accuracy=0.636719\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:31 INFO 140539772897088] Storing the best model with validation accuracy: 0.636719\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:31 Storing the best model with validation accuracy: 0.636719\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:31 Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:31 INFO 140539772897088] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:32 Epoch[1] Batch [20]#011Speed: 639.195 samples/sec#011accuracy=0.873512#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:32 INFO 140539772897088] Epoch[1] Batch [20]#011Speed: 639.195 samples/sec#011accuracy=0.873512#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:32 Epoch[1] Train-accuracy=0.878906\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:32 INFO 140539772897088] Epoch[1] Train-accuracy=0.878906\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:32 INFO 140539772897088] Epoch[1] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:32 Epoch[1] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:32 Epoch[1] Time cost=1.151\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:32 INFO 140539772897088] Epoch[1] Time cost=1.151\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:32 Epoch[1] Validation-accuracy=0.882812\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:32 INFO 140539772897088] Epoch[1] Validation-accuracy=0.882812\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:32 Storing the best model with validation accuracy: 0.882812\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:32 INFO 140539772897088] Storing the best model with validation accuracy: 0.882812\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:33 Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:33 INFO 140539772897088] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:34 Epoch[2] Batch [20]#011Speed: 600.704 samples/sec#011accuracy=0.943452#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:34 INFO 140539772897088] Epoch[2] Batch [20]#011Speed: 600.704 samples/sec#011accuracy=0.943452#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:34 INFO 140539772897088] Epoch[2] Train-accuracy=0.941406\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:34 Epoch[2] Train-accuracy=0.941406\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:34 INFO 140539772897088] Epoch[2] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:34 INFO 140539772897088] Epoch[2] Time cost=1.230\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:34 Epoch[2] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:34 Epoch[2] Time cost=1.230\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:34 Epoch[2] Validation-accuracy=0.925781\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:34 INFO 140539772897088] Epoch[2] Validation-accuracy=0.925781\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:34 Storing the best model with validation accuracy: 0.925781\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:34 INFO 140539772897088] Storing the best model with validation accuracy: 0.925781\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:34 Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:34 INFO 140539772897088] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\n",
      "2019-01-11 01:33:21 Training - Training image download completed. Training in progress.\u001b[31m2019-01-11 01:33:35 Epoch[3] Batch [20]#011Speed: 642.131 samples/sec#011accuracy=0.946429#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:35 INFO 140539772897088] Epoch[3] Batch [20]#011Speed: 642.131 samples/sec#011accuracy=0.946429#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:36 Epoch[3] Train-accuracy=0.949219\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:36 INFO 140539772897088] Epoch[3] Train-accuracy=0.949219\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:36 Epoch[3] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:36 INFO 140539772897088] Epoch[3] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:36 INFO 140539772897088] Epoch[3] Time cost=1.140\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:36 Epoch[3] Time cost=1.140\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:36 Epoch[3] Validation-accuracy=0.953125\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:36 INFO 140539772897088] Epoch[3] Validation-accuracy=0.953125\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:36 Storing the best model with validation accuracy: 0.953125\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:36 INFO 140539772897088] Storing the best model with validation accuracy: 0.953125\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:36 Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:36 INFO 140539772897088] Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:37 Epoch[4] Batch [20]#011Speed: 644.880 samples/sec#011accuracy=0.946429#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:37 INFO 140539772897088] Epoch[4] Batch [20]#011Speed: 644.880 samples/sec#011accuracy=0.946429#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:37 Epoch[4] Train-accuracy=0.950521\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:37 INFO 140539772897088] Epoch[4] Train-accuracy=0.950521\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:37 Epoch[4] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:37 INFO 140539772897088] Epoch[4] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:37 Epoch[4] Time cost=1.139\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:37 INFO 140539772897088] Epoch[4] Time cost=1.139\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:37 Epoch[4] Validation-accuracy=0.916667\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:37 INFO 140539772897088] Epoch[4] Validation-accuracy=0.916667\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:39 Epoch[5] Batch [20]#011Speed: 643.921 samples/sec#011accuracy=0.965774#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:39 INFO 140539772897088] Epoch[5] Batch [20]#011Speed: 643.921 samples/sec#011accuracy=0.965774#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:39 Epoch[5] Train-accuracy=0.960938\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:39 INFO 140539772897088] Epoch[5] Train-accuracy=0.960938\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:39 INFO 140539772897088] Epoch[5] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:39 Epoch[5] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:39 Epoch[5] Time cost=1.139\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:39 INFO 140539772897088] Epoch[5] Time cost=1.139\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:39 Epoch[5] Validation-accuracy=0.949219\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:39 INFO 140539772897088] Epoch[5] Validation-accuracy=0.949219\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:40 Epoch[6] Batch [20]#011Speed: 642.872 samples/sec#011accuracy=0.976190#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:40 INFO 140539772897088] Epoch[6] Batch [20]#011Speed: 642.872 samples/sec#011accuracy=0.976190#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:40 Epoch[6] Train-accuracy=0.979167\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:40 INFO 140539772897088] Epoch[6] Train-accuracy=0.979167\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:40 Epoch[6] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:40 INFO 140539772897088] Epoch[6] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:40 INFO 140539772897088] Epoch[6] Time cost=1.138\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:40 Epoch[6] Time cost=1.138\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:40 Epoch[6] Validation-accuracy=0.949219\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:40 INFO 140539772897088] Epoch[6] Validation-accuracy=0.949219\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:42 Epoch[7] Batch [20]#011Speed: 649.857 samples/sec#011accuracy=0.979167#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:42 INFO 140539772897088] Epoch[7] Batch [20]#011Speed: 649.857 samples/sec#011accuracy=0.979167#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:42 Epoch[7] Train-accuracy=0.979167\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:42 INFO 140539772897088] Epoch[7] Train-accuracy=0.979167\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:42 INFO 140539772897088] Epoch[7] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:42 Epoch[7] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:42 Epoch[7] Time cost=1.130\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:42 INFO 140539772897088] Epoch[7] Time cost=1.130\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:42 Epoch[7] Validation-accuracy=0.925781\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:42 INFO 140539772897088] Epoch[7] Validation-accuracy=0.925781\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:43 Epoch[8] Batch [20]#011Speed: 573.699 samples/sec#011accuracy=0.976190#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:43 INFO 140539772897088] Epoch[8] Batch [20]#011Speed: 573.699 samples/sec#011accuracy=0.976190#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:43 INFO 140539772897088] Epoch[8] Train-accuracy=0.979167\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:43 Epoch[8] Train-accuracy=0.979167\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:43 Epoch[8] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:43 INFO 140539772897088] Epoch[8] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:43 Epoch[8] Time cost=1.256\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:43 INFO 140539772897088] Epoch[8] Time cost=1.256\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:43 Epoch[8] Validation-accuracy=0.945312\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:43 INFO 140539772897088] Epoch[8] Validation-accuracy=0.945312\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:45 Epoch[9] Batch [20]#011Speed: 629.658 samples/sec#011accuracy=0.985119#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:45 INFO 140539772897088] Epoch[9] Batch [20]#011Speed: 629.658 samples/sec#011accuracy=0.985119#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:45 Epoch[9] Train-accuracy=0.986979\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:45 INFO 140539772897088] Epoch[9] Train-accuracy=0.986979\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:45 Epoch[9] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:45 INFO 140539772897088] Epoch[9] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:45 Epoch[9] Time cost=1.160\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:45 INFO 140539772897088] Epoch[9] Time cost=1.160\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:45 Epoch[9] Validation-accuracy=0.937500\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:45 INFO 140539772897088] Epoch[9] Validation-accuracy=0.937500\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:46 Epoch[10] Batch [20]#011Speed: 646.066 samples/sec#011accuracy=0.998512#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:46 INFO 140539772897088] Epoch[10] Batch [20]#011Speed: 646.066 samples/sec#011accuracy=0.998512#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:46 Epoch[10] Train-accuracy=0.998698\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:46 INFO 140539772897088] Epoch[10] Train-accuracy=0.998698\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:46 INFO 140539772897088] Epoch[10] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:46 Epoch[10] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:46 INFO 140539772897088] Epoch[10] Time cost=1.134\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:46 Epoch[10] Time cost=1.134\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:46 Epoch[10] Validation-accuracy=0.984375\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:46 INFO 140539772897088] Epoch[10] Validation-accuracy=0.984375\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:47 Storing the best model with validation accuracy: 0.984375\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:47 INFO 140539772897088] Storing the best model with validation accuracy: 0.984375\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:47 Saved checkpoint to \"/opt/ml/model/image-classification-0011.params\"\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:47 INFO 140539772897088] Saved checkpoint to \"/opt/ml/model/image-classification-0011.params\"\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:48 Epoch[11] Batch [20]#011Speed: 639.720 samples/sec#011accuracy=0.998512#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:48 INFO 140539772897088] Epoch[11] Batch [20]#011Speed: 639.720 samples/sec#011accuracy=0.998512#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:48 Epoch[11] Train-accuracy=0.998698\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:48 INFO 140539772897088] Epoch[11] Train-accuracy=0.998698\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:48 INFO 140539772897088] Epoch[11] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:48 Epoch[11] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:48 INFO 140539772897088] Epoch[11] Time cost=1.143\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:48 Epoch[11] Time cost=1.143\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:48 Epoch[11] Validation-accuracy=0.972656\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:48 INFO 140539772897088] Epoch[11] Validation-accuracy=0.972656\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:49 Epoch[12] Batch [20]#011Speed: 642.561 samples/sec#011accuracy=0.991071#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:49 INFO 140539772897088] Epoch[12] Batch [20]#011Speed: 642.561 samples/sec#011accuracy=0.991071#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:49 INFO 140539772897088] Epoch[12] Train-accuracy=0.990885\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:49 INFO 140539772897088] Epoch[12] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:49 INFO 140539772897088] Epoch[12] Time cost=1.140\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:49 Epoch[12] Train-accuracy=0.990885\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:49 Epoch[12] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:49 Epoch[12] Time cost=1.140\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:50 Epoch[12] Validation-accuracy=0.972656\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:50 INFO 140539772897088] Epoch[12] Validation-accuracy=0.972656\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:51 Epoch[13] Batch [20]#011Speed: 642.073 samples/sec#011accuracy=0.982143#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:51 INFO 140539772897088] Epoch[13] Batch [20]#011Speed: 642.073 samples/sec#011accuracy=0.982143#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:51 Epoch[13] Train-accuracy=0.981771\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:51 INFO 140539772897088] Epoch[13] Train-accuracy=0.981771\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:51 Epoch[13] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:51 Epoch[13] Time cost=1.140\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:51 INFO 140539772897088] Epoch[13] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:51 INFO 140539772897088] Epoch[13] Time cost=1.140\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:51 Epoch[13] Validation-accuracy=0.953125\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:51 INFO 140539772897088] Epoch[13] Validation-accuracy=0.953125\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:52 Epoch[14] Batch [20]#011Speed: 645.289 samples/sec#011accuracy=0.986607#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:52 INFO 140539772897088] Epoch[14] Batch [20]#011Speed: 645.289 samples/sec#011accuracy=0.986607#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:52 Epoch[14] Train-accuracy=0.988281\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:52 INFO 140539772897088] Epoch[14] Train-accuracy=0.988281\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:52 INFO 140539772897088] Epoch[14] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:52 Epoch[14] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:52 Epoch[14] Time cost=1.142\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:52 INFO 140539772897088] Epoch[14] Time cost=1.142\u001b[0m\n",
      "\u001b[31m2019-01-11 01:33:53 Epoch[14] Validation-accuracy=0.980469\u001b[0m\n",
      "\u001b[31m[01/11/2019 01:33:53 INFO 140539772897088] Epoch[14] Validation-accuracy=0.980469\u001b[0m\n",
      "\n",
      "2019-01-11 01:34:09 Uploading - Uploading generated training model\n",
      "2019-01-11 01:34:09 Completed - Training job completed\n",
      "Billable seconds: 162\n"
     ]
    }
   ],
   "source": [
    "ic.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: image-classification-2019-01-11-01-35-37-352\n",
      "INFO:sagemaker:Creating endpoint with name image-classification-2019-01-11-01-29-14-953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "ic_classifier = ic.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = 'cropped_test/split128/'\n",
    "no_kiwis = os.listdir(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: label - no_kiwi, probability - 0.9999655485153198\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, json\n",
    "from IPython.display import Image\n",
    "\n",
    "# test image\n",
    "file_name = dd  + random.choice(no_kiwis)\n",
    "with open(file_name, 'rb') as f:\n",
    "    image = bytearray(f.read())\n",
    "    \n",
    "ic_classifier.content_type = 'application/x-image'\n",
    "result = json.loads(ic_classifier.predict(image))\n",
    "# the result will output the probabilities for all classes\n",
    "# find the class with maximum probability and print the class index\n",
    "index = np.argmax(result)\n",
    "object_categories = ['kiwi', 'no_kiwi'] \n",
    "print(\"Result: label - \" + object_categories[index] + \", probability - \" + str(result[index]))\n",
    "Image(file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.449548239586875e-05, 0.9999655485153198]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: image-classification-2019-01-11-01-29-14-953\n"
     ]
    }
   ],
   "source": [
    "ic_classifier.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
